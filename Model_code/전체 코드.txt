<ì…€1>
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.preprocessing import image
import numpy as np

# -----------------------------
# 1. ë°ì´í„° ì¤€ë¹„
# -----------------------------
train_dir = "/content/drive/MyDrive/brain_ct/train"
test_dir = "/content/drive/MyDrive/brain_ct/test"

img_size = (224, 224)
batch_size = 32

train_datagen = ImageDataGenerator(
    rescale=1./255,
    horizontal_flip=True,
    rotation_range=10,
    zoom_range=0.1
)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='binary'
)
test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='binary',
    shuffle=False
)

# -----------------------------
# 2. CNN ëª¨ë¸ ì •ì˜
# -----------------------------
def create_simple_cnn(input_shape=(224,224,3)):
    model = models.Sequential([
        layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),
        layers.MaxPooling2D(2,2),
        layers.Conv2D(64, (3,3), activation='relu'),
        layers.MaxPooling2D(2,2),
        layers.Conv2D(128, (3,3), activation='relu'),
        layers.MaxPooling2D(2,2),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dense(1, activation='sigmoid')
    ])
    return model

cnn_model = create_simple_cnn()
cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
cnn_model.summary()

# -----------------------------
# 3. í•™ìŠµ
# -----------------------------
early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

cnn_model.fit(
    train_generator,
    validation_data=test_generator,
    epochs=10,
    callbacks=[early_stop]
)

# -----------------------------
# 4. ëª¨ë¸ ì €ì¥
# -----------------------------
cnn_model.save("/content/drive/MyDrive/cnn_brain_ct.h5")

# -----------------------------
# 5. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •í™•ë„
# -----------------------------
loss, acc = cnn_model.evaluate(test_generator)
print(f"CNN ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì •í™•ë„: {acc*100:.2f}%")

# -----------------------------
# 6. ì„ì˜ ì´ë¯¸ì§€ ì˜ˆì¸¡
# -----------------------------
img_path = "/content/drive/MyDrive/brain_ct/test/hemorrhage/ds1_0_hemorrhage_1026_IMG-0001-00073.jpg"
img = image.load_img(img_path, target_size=img_size)
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = x / 255.0

pred = cnn_model.predict(x)[0][0]
label = "hemorrhage" if pred >= 0.5 else "normal"
print(f"CNN ëª¨ë¸ ì˜ˆì¸¡: {label} ({pred:.4f})")


<ì…€2>
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.preprocessing import image
from tensorflow.keras.optimizers import Adam
import numpy as np
from google.colab import drive


drive.mount('/content/drive')

import os
print(os.listdir("/content/drive/MyDrive"))

print(os.listdir("/content/drive/MyDrive/brain_ct"))


<ì…€3>
# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (í•„ìš” ì‹œ)
!pip install tensorflow opencv-python matplotlib numpy pandas scikit-learn tqdm

# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import os
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tqdm import tqdm
from sklearn.model_selection import train_test_split

# êµ¬ê¸€ ë“œë¼ì´ë¸Œ ê²½ë¡œ ì„¤ì •
base_path = "/content/drive/MyDrive"

# ì‘ì—… í´ë”ë¥¼ í•˜ë‚˜ ì§€ì • (ì›í•˜ëŠ” í´ë”ëª…ìœ¼ë¡œ ë°”ê¿”ë„ ë¨)
project_path = os.path.join(base_path, "Colab Notebooks")
print("ì‘ì—… ê²½ë¡œ:", project_path)

# í´ë” ëª©ë¡ í™•ì¸ (ì •ìƒ ì ‘ê·¼ í™•ì¸)
print(os.listdir(project_path))


<ì…€4>
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.optimizers import Adam

# ì˜ˆì‹œ ë°ì´í„° (ì—¬ê¸°ì„œëŠ” ëœë¤ ë°ì´í„°ë¡œ ëŒ€ì²´)
# ì‹¤ì œë¡œëŠ” CT ì´ë¯¸ì§€ì™€ ë¼ë²¨ë¡œ ëŒ€ì²´í•´ì•¼ í•¨
import numpy as np
num_samples = 100
img_height, img_width = 64, 64
num_classes = 2

X_train = np.random.rand(num_samples, img_height, img_width, 1).astype(np.float32)
y_train = tf.keras.utils.to_categorical(np.random.randint(0, num_classes, num_samples), num_classes)

# í…ŒìŠ¤íŠ¸í•  í•˜ì´í¼íŒŒë¼ë¯¸í„°
learning_rates = [0.01, 0.001, 0.0001]
epochs_list = [5]  # ê° ì—í­ì€ 5ë¡œ ê³ ì •

# ê²°ê³¼ ì €ì¥ìš©
results = {}

for lr in learning_rates:
    for epochs in epochs_list:
        # ëª¨ë¸ ì •ì˜
        model = Sequential([
            Conv2D(32, (3,3), activation='relu', input_shape=(img_height, img_width,1)),
            MaxPooling2D((2,2)),
            Flatten(),
            Dense(64, activation='relu'),
            Dense(num_classes, activation='softmax')
        ])
        
        # ì˜µí‹°ë§ˆì´ì € ì„¤ì •
        optimizer = Adam(learning_rate=lr)
        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])
        
        # í•™ìŠµ
        print(f"Training with learning rate={lr}, epochs={epochs}")
        history = model.fit(X_train, y_train, epochs=epochs, batch_size=8, verbose=1)
        
        # ìµœì¢… ì •í™•ë„ ì €ì¥
        results[f"lr_{lr}_epochs_{epochs}"] = history.history['accuracy'][-1]

print("ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
print(results)


<ì…€5>
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

# -----------------------------
# í•™ìŠµë¥  í›„ë³´
# -----------------------------
learning_rates = [0.01, 0.001, 0.0001]

results = {}

# -----------------------------
# í•™ìŠµë¥ ë³„ ì‹¤í—˜
# -----------------------------
for lr in learning_rates:
    print("\n====================================")
    print(f"ğŸ“Œ Learning Rate = {lr} ì‹¤í—˜ ì‹œì‘")
    print("====================================")

    # ëª¨ë¸ ìƒˆë¡œ ìƒì„±
    model = create_simple_cnn()
    model.compile(
        optimizer=Adam(learning_rate=lr),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )

    # ì¡°ê¸° ì¢…ë£Œ
    early_stop = EarlyStopping(
        monitor='val_loss',
        patience=2,
        restore_best_weights=True
    )

    # ëª¨ë¸ í•™ìŠµ (epochs = 5)
    history = model.fit(
        train_generator,
        validation_data=test_generator,
        epochs=5,
        callbacks=[early_stop],
        verbose=1
    )

    # ê²€ì¦ ì •í™•ë„ ì €ì¥
    val_acc = max(history.history['val_accuracy'])
    results[lr] = val_acc
    print(f"â¡ï¸ LR {lr} ìµœì¢… ê²€ì¦ ì •í™•ë„: {val_acc:.4f}")

# -----------------------------
# ê²°ê³¼ ë¹„êµ ì¶œë ¥
# -----------------------------
print("\n===== í•™ìŠµë¥ ë³„ ì„±ëŠ¥ ìš”ì•½ =====")
for lr, acc in results.items():
    print(f"LR={lr} â†’ Val Accuracy = {acc:.4f}")

# ê°€ì¥ ì¢‹ì€ í•™ìŠµë¥  ì°¾ê¸°
best_lr = max(results, key=results.get)
print(f"\nğŸ¯ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ í•™ìŠµë¥ : {best_lr}")


<ì…€6>
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing import image
import numpy as np

# -----------------------------
# 1. ë°ì´í„° ì¤€ë¹„
# -----------------------------
train_dir = "/content/drive/MyDrive/brain_ct/train"
test_dir = "/content/drive/MyDrive/brain_ct/test"

img_size = (224, 224)
batch_size = 32

train_datagen = ImageDataGenerator(
    rescale=1./255,
    horizontal_flip=True,
    rotation_range=10,
    zoom_range=0.1
)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='binary'
)
test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='binary',
    shuffle=False
)

# -----------------------------
# 2. ResNet from scratch ì •ì˜
# -----------------------------
def create_resnet_from_scratch(input_shape=(224,224,3)):
    inputs = layers.Input(shape=input_shape)
    x = layers.Conv2D(64, (7,7), strides=2, padding='same', activation='relu')(inputs)
    x = layers.MaxPooling2D(3, strides=2, padding='same')(x)
    for filters in [64,128,256]:
        x = layers.Conv2D(filters, (3,3), activation='relu', padding='same')(x)
        x = layers.Conv2D(filters, (3,3), activation='relu', padding='same')(x)
        x = layers.MaxPooling2D(2,2)(x)
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(128, activation='relu')(x)
    outputs = layers.Dense(1, activation='sigmoid')(x)
    model = Model(inputs, outputs)
    return model

resnet_scratch = create_resnet_from_scratch()
resnet_scratch.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
resnet_scratch.summary()

# -----------------------------
# 3. í•™ìŠµ
# -----------------------------
early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

resnet_scratch.fit(
    train_generator,
    validation_data=test_generator,
    epochs=10,
    callbacks=[early_stop]
)

# -----------------------------
# 4. ëª¨ë¸ ì €ì¥
# -----------------------------
resnet_scratch.save("/content/drive/MyDrive/resnet_scratch_brain_ct.h5")

# -----------------------------
# 5. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •í™•ë„
# -----------------------------
loss, acc = resnet_scratch.evaluate(test_generator)
print(f"ResNet scratch í…ŒìŠ¤íŠ¸ ì •í™•ë„: {acc*100:.2f}%")

# -----------------------------
# 6. ì„ì˜ ì´ë¯¸ì§€ ì˜ˆì¸¡
# -----------------------------
img_path = "/content/drive/MyDrive/brain_ct/test/hemorrhage/ds1_0_hemorrhage_1026_IMG-0001-00073.jpg"
img = image.load_img(img_path, target_size=img_size)
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = x / 255.0

pred = resnet_scratch.predict(x)[0][0]
label = "hemorrhage" if pred >= 0.5 else "normal"
print(f"ResNet scratch ì˜ˆì¸¡: {label} ({pred:.4f})")


<ì…€7>
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.preprocessing import image
import numpy as np

# -----------------------------
# 1. ë°ì´í„° ì¤€ë¹„
# -----------------------------
train_dir = "/content/drive/MyDrive/brain_ct/train"
test_dir = "/content/drive/MyDrive/brain_ct/test"

img_size = (224, 224)
batch_size = 32

train_datagen = ImageDataGenerator(
    rescale=1./255,
    horizontal_flip=True,
    rotation_range=10,
    zoom_range=0.1
)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='binary'
)
test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='binary',
    shuffle=False
)

# -----------------------------
# 2. ResNet50 ì „ì´í•™ìŠµ ì •ì˜ (freeze)
# -----------------------------
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))
for layer in base_model.layers:
    layer.trainable = False

x = layers.GlobalAveragePooling2D()(base_model.output)
x = layers.Dense(128, activation='relu')(x)
outputs = layers.Dense(1, activation='sigmoid')(x)

resnet_transfer = Model(inputs=base_model.input, outputs=outputs)
resnet_transfer.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
resnet_transfer.summary()

# -----------------------------
# 3. í•™ìŠµ
# -----------------------------
early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

resnet_transfer.fit(
    train_generator,
    validation_data=test_generator,
    epochs=10,
    callbacks=[early_stop]
)

# -----------------------------
# 4. ëª¨ë¸ ì €ì¥
# -----------------------------
resnet_transfer.save("/content/drive/MyDrive/resnet_transfer_brain_ct.h5")

# -----------------------------
# 5. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •í™•ë„
# -----------------------------
loss, acc = resnet_transfer.evaluate(test_generator)
print(f"ResNet50 transfer í…ŒìŠ¤íŠ¸ ì •í™•ë„: {acc*100:.2f}%")

# -----------------------------
# 6. ì„ì˜ ì´ë¯¸ì§€ ì˜ˆì¸¡
# -----------------------------
img_path = "/content/drive/MyDrive/brain_ct/test/hemorrhage/ds1_0_hemorrhage_1026_IMG-0001-00073.jpg"
img = image.load_img(img_path, target_size=img_size)
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = x / 255.0

pred = resnet_transfer.predict(x)[0][0]
label = "hemorrhage" if pred >= 0.5 else "normal"
print(f"ResNet50 transfer ì˜ˆì¸¡: {label} ({pred:.4f})")



<ì…€8>
from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input

# -----------------------------
# 1. ë°ì´í„° ì¤€ë¹„
# -----------------------------
train_dir = "/content/drive/MyDrive/brain_ct/train"
test_dir = "/content/drive/MyDrive/brain_ct/test"

# ë°ì´í„° ì¦ê°• (preprocess_input í¬í•¨)
train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest'
)

test_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input
)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(128,128),  # ì´ë¯¸ì§€ í¬ê¸° ì¶•ì†Œ
    batch_size=32,           # ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì¦ê°€
    class_mode='binary'
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(128,128),
    batch_size=32,
    class_mode='binary',
    shuffle=False
)

# -----------------------------
# 2. ResNet50 base model ë¶ˆëŸ¬ì˜¤ê¸° (pretrained)
# -----------------------------
base_model = ResNet50(
    weights='imagenet',
    include_top=False,
    input_shape=(128,128,3)
)

# -----------------------------
# 3. Top layers êµ¬ì„±
# -----------------------------
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(128, activation='relu')(x)
x = Dropout(0.3)(x)
predictions = Dense(1, activation='sigmoid')(x)

model = Model(inputs=base_model.input, outputs=predictions)

# -----------------------------
# 4. í•™ìŠµ: base model freeze (Denseë§Œ í•™ìŠµ)
# -----------------------------
for layer in base_model.layers:
    layer.trainable = False

model.compile(
    optimizer=Adam(learning_rate=1e-3),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

history = model.fit(
    train_generator,
    epochs=5,                 # epoch ìµœì†Œí™”
    validation_data=test_generator
)

# -----------------------------
# 5. ëª¨ë¸ ì €ì¥
# -----------------------------
model.save("/content/drive/MyDrive/resnet_transfer_fast_brain_ct.h5")

