# ============================================================
# ResNet50 Fine-tuning ìµœì í™” ì½”ë“œ (ëª©í‘œ: 90% ì •í™•ë„)
# ============================================================

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
import numpy as np

# GPU ë©”ëª¨ë¦¬ ì¦ê°€ ë°©ì§€ ì„¤ì •
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
    except RuntimeError as e:
        print(e)

# -----------------------------
# 1. ë°ì´í„° ê²½ë¡œ ì„¤ì •
# -----------------------------
train_dir = "/content/drive/MyDrive/brain_ct/train"
test_dir = "/content/drive/MyDrive/brain_ct/test"

img_size = (224, 224)
batch_size = 32

# -----------------------------
# 2. ê°•í™”ëœ Data Augmentation
# -----------------------------
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,           # 10 â†’ 20 ì¦ê°€
    width_shift_range=0.15,      # ìƒˆë¡œ ì¶”ê°€
    height_shift_range=0.15,     # ìƒˆë¡œ ì¶”ê°€
    horizontal_flip=True,
    zoom_range=0.2,              # 0.1 â†’ 0.2 ì¦ê°€
    brightness_range=[0.8, 1.2], # ë°ê¸° ì¡°ì • ì¶”ê°€
    fill_mode='nearest'
)

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='binary',
    shuffle=True
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='binary',
    shuffle=False
)

# í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
print("\n=== ë°ì´í„°ì…‹ ì •ë³´ ===")
print(f"Train samples: {train_generator.samples}")
print(f"Test samples: {test_generator.samples}")
print(f"Class indices: {train_generator.class_indices}")
print(f"Class distribution: {np.bincount(train_generator.classes)}")

# -----------------------------
# 3. Class Weights ê³„ì‚° (í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬)
# -----------------------------
from sklearn.utils.class_weight import compute_class_weight

# í˜„ì¬ ë°ì´í„°: hemorrhage(2152) vs normal(3371)
# hemorrhageì— ë” ë†’ì€ ê°€ì¤‘ì¹˜ ë¶€ì—¬
class_weights_array = compute_class_weight(
    'balanced',
    classes=np.unique(train_generator.classes),
    y=train_generator.classes
)

# hemorrhage ê°€ì¤‘ì¹˜ ì¶”ê°€ ê°•í™” (1.5ë°°)
class_weights = {
    0: class_weights_array[0],
    1: class_weights_array[1] * 1.3  # hemorrhage ê°€ì¤‘ì¹˜ 30% ì¶”ê°€
}

print(f"\nClass weights: {class_weights}")

# -----------------------------
# 4. ResNet50 Fine-tuning ëª¨ë¸ êµ¬ì„± (2ë‹¨ê³„)
# -----------------------------
def create_resnet50_model(input_shape=(224, 224, 3), trainable_base=False):
    """
    ResNet50 Fine-tuning ëª¨ë¸ ìƒì„±

    Args:
        input_shape: ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°
        trainable_base: Trueë©´ base model ì¼ë¶€ í•™ìŠµ, Falseë©´ freeze
    """
    # ImageNet pretrained ResNet50
    base_model = ResNet50(
        weights='imagenet',
        include_top=False,
        input_shape=input_shape
    )

    # Base model freeze ì„¤ì •
    if not trainable_base:
        # Stage 1: ì „ì²´ freeze
        for layer in base_model.layers:
            layer.trainable = False
    else:
        # Stage 2: ë§ˆì§€ë§‰ 30ê°œ ë ˆì´ì–´ë§Œ unfreeze
        for layer in base_model.layers[:-30]:
            layer.trainable = False
        for layer in base_model.layers[-30:]:
            layer.trainable = True

    # Top layers ì¶”ê°€
    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(256, activation='relu')(x)  # 128 â†’ 256 ì¦ê°€
    x = Dropout(0.5)(x)  # 0.3 â†’ 0.5 ì¦ê°€ (overfitting ë°©ì§€)
    x = Dense(128, activation='relu')(x)
    x = Dropout(0.3)(x)
    predictions = Dense(1, activation='sigmoid')(x)

    model = Model(inputs=base_model.input, outputs=predictions)

    return model, base_model

# -----------------------------
# 5. Callbacks ì„¤ì •
# -----------------------------
callbacks_stage1 = [
    EarlyStopping(
        monitor='val_loss',
        patience=3,
        restore_best_weights=True,
        verbose=1
    ),
    ModelCheckpoint(
        filepath='/content/drive/MyDrive/resnet50_stage1_best.h5',
        monitor='val_accuracy',
        save_best_only=True,
        verbose=1
    )
]

callbacks_stage2 = [
    EarlyStopping(
        monitor='val_loss',
        patience=5,
        restore_best_weights=True,
        verbose=1
    ),
    ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=3,
        min_lr=1e-7,
        verbose=1
    ),
    ModelCheckpoint(
        filepath='/content/drive/MyDrive/resnet50_stage2_best.h5',
        monitor='val_accuracy',
        save_best_only=True,
        verbose=1
    )
]

# -----------------------------
# 6. Stage 1 í•™ìŠµ (Base model freeze)
# -----------------------------
print("\n" + "="*60)
print("ğŸš€ Stage 1: Top layersë§Œ í•™ìŠµ (Base model freeze)")
print("="*60)

model, base_model = create_resnet50_model(trainable_base=False)

model.compile(
    optimizer=Adam(learning_rate=1e-3),  # ë†’ì€ LRë¡œ ë¹ ë¥´ê²Œ í•™ìŠµ
    loss='binary_crossentropy',
    metrics=['accuracy']
)

print(f"\nTrainable parameters: {sum([np.prod(v.get_shape()) for v in model.trainable_weights]):,}")
print(f"Non-trainable parameters: {sum([np.prod(v.get_shape()) for v in model.non_trainable_weights]):,}")

history_stage1 = model.fit(
    train_generator,
    validation_data=test_generator,
    epochs=5,
    class_weight=class_weights,
    callbacks=callbacks_stage1,
    verbose=1
)

# Stage 1 ê²°ê³¼ ì¶œë ¥
val_acc_stage1 = max(history_stage1.history['val_accuracy'])
print(f"\nâœ… Stage 1 ì™„ë£Œ - ìµœê³  ê²€ì¦ ì •í™•ë„: {val_acc_stage1*100:.2f}%")

# -----------------------------
# 7. Stage 2 í•™ìŠµ (ë§ˆì§€ë§‰ ë ˆì´ì–´ unfreeze)
# -----------------------------
print("\n" + "="*60)
print("ğŸš€ Stage 2: ë§ˆì§€ë§‰ Conv block fine-tuning")
print("="*60)

# ë§ˆì§€ë§‰ 30ê°œ ë ˆì´ì–´ ì–¸í”„ë¦¬ì¦ˆ
for layer in base_model.layers[-30:]:
    layer.trainable = True

model.compile(
    optimizer=Adam(learning_rate=1e-4),  # ë‚®ì€ LRë¡œ ì„¬ì„¸í•˜ê²Œ fine-tuning
    loss='binary_crossentropy',
    metrics=['accuracy']
)

print(f"\nTrainable parameters: {sum([np.prod(v.get_shape()) for v in model.trainable_weights]):,}")
print(f"Non-trainable parameters: {sum([np.prod(v.get_shape()) for v in model.non_trainable_weights]):,}")

history_stage2 = model.fit(
    train_generator,
    validation_data=test_generator,
    epochs=25,
    class_weight=class_weights,
    callbacks=callbacks_stage2,
    verbose=1
)

# Stage 2 ê²°ê³¼ ì¶œë ¥
val_acc_stage2 = max(history_stage2.history['val_accuracy'])
print(f"\nâœ… Stage 2 ì™„ë£Œ - ìµœê³  ê²€ì¦ ì •í™•ë„: {val_acc_stage2*100:.2f}%")

# -----------------------------
# 8. ìµœì¢… ëª¨ë¸ ì €ì¥
# -----------------------------
model.save("/content/drive/MyDrive/resnet50_final_optimized.h5")
print("\nğŸ’¾ ìµœì¢… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: resnet50_final_optimized.h5")

# -----------------------------
# 9. ìµœì¢… í‰ê°€
# -----------------------------
print("\n" + "="*60)
print("ğŸ“Š ìµœì¢… ëª¨ë¸ í‰ê°€")
print("="*60)

loss, accuracy = model.evaluate(test_generator, verbose=1)
print(f"\nìµœì¢… Test Loss: {loss:.4f}")
print(f"ìµœì¢… Test Accuracy: {accuracy*100:.2f}%")

if accuracy >= 0.90:
    print("\nğŸ‰ ëª©í‘œ ë‹¬ì„±! 90% ì´ìƒ ì •í™•ë„ ë‹¬ì„±!")
else:
    print(f"\nâš ï¸  í˜„ì¬ {accuracy*100:.2f}% - 90% ëª©í‘œê¹Œì§€ {(0.90-accuracy)*100:.2f}% ë¶€ì¡±")

# -----------------------------
# 10. ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
# -----------------------------
from tensorflow.keras.preprocessing import image

print("\n" + "="*60)
print("ğŸ” ì‹¤ì œ ì´ë¯¸ì§€ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸")
print("="*60)

# hemorrhage ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸
img_path_hem = "/content/drive/MyDrive/brain_ct/test/hemorrhage/ds1_0_hemorrhage_1026_IMG-0001-00073.jpg"
img_hem = image.load_img(img_path_hem, target_size=img_size)
x_hem = image.img_to_array(img_hem)
x_hem = np.expand_dims(x_hem, axis=0)
x_hem = x_hem / 255.0

pred_hem = model.predict(x_hem)[0][0]
label_hem = "hemorrhage" if pred_hem >= 0.5 else "normal"
print(f"\n1. Hemorrhage ì´ë¯¸ì§€ ì˜ˆì¸¡:")
print(f"   - ì˜ˆì¸¡ê°’: {pred_hem:.4f}")
print(f"   - íŒì •: {label_hem}")
print(f"   - ì •ë‹µ: hemorrhage")
print(f"   - ê²°ê³¼: {'âœ… ì •ë‹µ' if label_hem == 'hemorrhage' else 'âŒ ì˜¤ë‹µ'}")

# normal ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸ (íŒŒì¼ ê²½ë¡œëŠ” ì‹¤ì œ ê²½ë¡œë¡œ ìˆ˜ì • í•„ìš”)
try:
    import glob
    normal_images = glob.glob("/content/drive/MyDrive/brain_ct/test/normal/*.jpg")
    if normal_images:
        img_path_normal = normal_images[0]
        img_normal = image.load_img(img_path_normal, target_size=img_size)
        x_normal = image.img_to_array(img_normal)
        x_normal = np.expand_dims(x_normal, axis=0)
        x_normal = x_normal / 255.0

        pred_normal = model.predict(x_normal)[0][0]
        label_normal = "hemorrhage" if pred_normal >= 0.5 else "normal"
        print(f"\n2. Normal ì´ë¯¸ì§€ ì˜ˆì¸¡:")
        print(f"   - ì˜ˆì¸¡ê°’: {pred_normal:.4f}")
        print(f"   - íŒì •: {label_normal}")
        print(f"   - ì •ë‹µ: normal")
        print(f"   - ê²°ê³¼: {'âœ… ì •ë‹µ' if label_normal == 'normal' else 'âŒ ì˜¤ë‹µ'}")
except:
    print("\n2. Normal ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

# -----------------------------
# 11. í•™ìŠµ ê³¡ì„  ì‹œê°í™”
# -----------------------------
import matplotlib.pyplot as plt

# Stage 2 í•™ìŠµ ê³¡ì„ 
plt.figure(figsize=(14, 5))

plt.subplot(1, 2, 1)
plt.plot(history_stage2.history['accuracy'], label='Train Accuracy')
plt.plot(history_stage2.history['val_accuracy'], label='Val Accuracy')
plt.axhline(y=0.90, color='r', linestyle='--', label='90% Goal')
plt.title('Model Accuracy (Stage 2)')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)

plt.subplot(1, 2, 2)
plt.plot(history_stage2.history['loss'], label='Train Loss')
plt.plot(history_stage2.history['val_loss'], label='Val Loss')
plt.title('Model Loss (Stage 2)')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.savefig('/content/drive/MyDrive/training_curves.png', dpi=300, bbox_inches='tight')
print("\nğŸ“ˆ í•™ìŠµ ê³¡ì„  ì €ì¥ ì™„ë£Œ: training_curves.png")
plt.show()

print("\n" + "="*60)
print("âœ¨ ëª¨ë“  í•™ìŠµ ì™„ë£Œ!")
print("="*60)
