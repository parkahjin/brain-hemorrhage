"""
Grad-CAM (Gradient-weighted Class Activation Mapping) êµ¬í˜„

ëª¨ë¸ì´ ì–´ëŠ ë¶€ìœ„ë¥¼ ë³´ê³  íŒë‹¨í–ˆëŠ”ì§€ ì‹œê°í™”
ë‡Œì¶œí˜ˆ ì§„ë‹¨ì˜ ê·¼ê±°ë¥¼ ì œì‹œ
"""

import numpy as np
import cv2
import tensorflow as tf
from tensorflow import keras
from typing import Tuple, Optional
import matplotlib.pyplot as plt
import matplotlib.cm as cm


class GradCAM:
    """
    Grad-CAM êµ¬í˜„ í´ë˜ìŠ¤

    ResNet50 ë“± CNN ëª¨ë¸ì—ì„œ ë§ˆì§€ë§‰ Conv layerì˜ activationì„ ì¶”ì¶œí•˜ì—¬
    ì–´ëŠ ì˜ì—­ì´ ì˜ˆì¸¡ì— ì¤‘ìš”í•œì§€ íˆíŠ¸ë§µìœ¼ë¡œ ì‹œê°í™”
    """

    def __init__(self, model: keras.Model, layer_name: Optional[str] = None):
        """
        Args:
            model: í•™ìŠµëœ Keras ëª¨ë¸
            layer_name: Grad-CAMì„ ì ìš©í•  ë ˆì´ì–´ ì´ë¦„
                       Noneì´ë©´ ë§ˆì§€ë§‰ Conv layer ìë™ íƒìƒ‰
        """
        self.model = model

        # ë§ˆì§€ë§‰ Conv layer ì°¾ê¸°
        if layer_name is None:
            layer_name = self._find_last_conv_layer()

        self.layer_name = layer_name
        print(f"Grad-CAM ì ìš© ë ˆì´ì–´: {layer_name}")

    def _find_last_conv_layer(self) -> str:
        """
        ëª¨ë¸ì—ì„œ ë§ˆì§€ë§‰ Convolutional layer ì°¾ê¸°

        Returns:
            ë§ˆì§€ë§‰ Conv layerì˜ ì´ë¦„
        """
        for layer in reversed(self.model.layers):
            # Conv2D ë ˆì´ì–´ ì°¾ê¸°
            try:
                if hasattr(layer, 'output_shape') and len(layer.output_shape) == 4:  # (None, H, W, C)
                    return layer.name
                # Functional API ëª¨ë¸ì¸ ê²½ìš°
                elif hasattr(layer, 'output') and hasattr(layer.output, 'shape'):
                    if len(layer.output.shape) == 4:
                        return layer.name
            except:
                continue

        raise ValueError("ëª¨ë¸ì—ì„œ Convolutional layerë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    def generate_heatmap(self,
                        image: np.ndarray,
                        pred_index: Optional[int] = None) -> np.ndarray:
        """
        Grad-CAM íˆíŠ¸ë§µ ìƒì„±

        Args:
            image: ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ (1, H, W, 3)
            pred_index: ì˜ˆì¸¡ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ (Noneì´ë©´ ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ì‚¬ìš©)

        Returns:
            íˆíŠ¸ë§µ (0-1 ë²”ìœ„, H, W)
        """
        # Gradient ê³„ì‚°ì„ ìœ„í•œ ì„œë¸Œëª¨ë¸ ìƒì„±
        grad_model = keras.models.Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.layer_name).output,
                    self.model.output]
        )

        # Gradient ê³„ì‚°
        with tf.GradientTape() as tape:
            conv_outputs, predictions = grad_model(image)

            # Binary classificationì¸ ê²½ìš°
            if pred_index is None:
                pred_index = 0  # sigmoid output

            # ì˜ˆì¸¡ê°’ ì¶”ì¶œ
            if predictions.shape[-1] == 1:
                # Binary classification (sigmoid)
                class_channel = predictions[:, 0]
            else:
                # Multi-class (softmax)
                class_channel = predictions[:, pred_index]

        # Gradient ê³„ì‚°
        grads = tape.gradient(class_channel, conv_outputs)

        # Global Average Pooling on gradients
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

        # Conv outputsì™€ pooled gradientsë¥¼ ê³±í•˜ì—¬ ì¤‘ìš”ë„ ê°€ì¤‘ì¹˜ ì ìš©
        conv_outputs = conv_outputs[0]
        pooled_grads = pooled_grads.numpy()
        conv_outputs = conv_outputs.numpy()

        for i in range(len(pooled_grads)):
            conv_outputs[:, :, i] *= pooled_grads[i]

        # Channel-wise sum
        heatmap = np.sum(conv_outputs, axis=-1)

        # ReLU ì ìš© (ì–‘ìˆ˜ë§Œ ìœ ì§€)
        heatmap = np.maximum(heatmap, 0)

        # 0-1 ì •ê·œí™”
        if heatmap.max() > 0:
            heatmap /= heatmap.max()

        return heatmap

    def overlay_heatmap(self,
                       heatmap: np.ndarray,
                       original_image: np.ndarray,
                       alpha: float = 0.4,
                       colormap: int = cv2.COLORMAP_JET) -> np.ndarray:
        """
        íˆíŠ¸ë§µì„ ì›ë³¸ ì´ë¯¸ì§€ì— ì˜¤ë²„ë ˆì´

        Args:
            heatmap: Grad-CAM íˆíŠ¸ë§µ (0-1 ë²”ìœ„)
            original_image: ì›ë³¸ ì´ë¯¸ì§€ (H, W) or (H, W, 3)
            alpha: íˆ¬ëª…ë„ (0: ì›ë³¸ë§Œ, 1: íˆíŠ¸ë§µë§Œ)
            colormap: OpenCV ì»¬ëŸ¬ë§µ

        Returns:
            ì˜¤ë²„ë ˆì´ëœ ì´ë¯¸ì§€ (H, W, 3)
        """
        # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ íˆíŠ¸ë§µ ë¦¬ì‚¬ì´ì¦ˆ
        if len(original_image.shape) == 2:
            h, w = original_image.shape
        else:
            h, w = original_image.shape[:2]

        heatmap_resized = cv2.resize(heatmap, (w, h))

        # íˆíŠ¸ë§µì„ 0-255ë¡œ ë³€í™˜
        heatmap_uint8 = np.uint8(255 * heatmap_resized)

        # ì»¬ëŸ¬ë§µ ì ìš©
        heatmap_colored = cv2.applyColorMap(heatmap_uint8, colormap)

        # ì›ë³¸ ì´ë¯¸ì§€ë¥¼ RGBë¡œ ë³€í™˜ ë° ì •ê·œí™”
        if len(original_image.shape) == 2:
            original_rgb = cv2.cvtColor(original_image, cv2.COLOR_GRAY2RGB)
        else:
            original_rgb = original_image.copy()

        # ì›ë³¸ ì´ë¯¸ì§€ê°€ floatì´ë©´ uint8ë¡œ ë³€í™˜
        if original_rgb.dtype != np.uint8:
            if original_rgb.max() <= 1.0:
                original_rgb = (original_rgb * 255).astype(np.uint8)
            else:
                original_rgb = original_rgb.astype(np.uint8)

        # ì˜¤ë²„ë ˆì´
        overlayed = cv2.addWeighted(original_rgb, 1 - alpha, heatmap_colored, alpha, 0)

        return overlayed

    def explain_prediction(self,
                          image_path: str,
                          preprocessor,
                          threshold: float = 0.5) -> dict:
        """
        ì˜ˆì¸¡ ê²°ê³¼ë¥¼ Grad-CAMìœ¼ë¡œ ì„¤ëª…

        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            preprocessor: CTImagePreprocessor ì¸ìŠ¤í„´ìŠ¤
            threshold: Binary classification threshold

        Returns:
            dict with keys: prediction, heatmap, overlay, explanation
        """
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        preprocessed_image, original_image = preprocessor.preprocess(
            image_path, return_original=True
        )

        # ì˜ˆì¸¡
        prediction = self.model.predict(preprocessed_image, verbose=0)[0][0]
        predicted_class = "hemorrhage" if prediction >= threshold else "normal"

        # Grad-CAM íˆíŠ¸ë§µ ìƒì„±
        heatmap = self.generate_heatmap(preprocessed_image)

        # ì˜¤ë²„ë ˆì´ ìƒì„±
        overlay = self.overlay_heatmap(heatmap, original_image, alpha=0.4)

        # ì„¤ëª… í…ìŠ¤íŠ¸ ìƒì„±
        explanation = self._generate_explanation_text(
            heatmap, prediction, predicted_class
        )

        return {
            'prediction': prediction,
            'predicted_class': predicted_class,
            'confidence': prediction if prediction >= 0.5 else 1 - prediction,
            'heatmap': heatmap,
            'overlay': overlay,
            'original': original_image,
            'explanation': explanation
        }

    def _generate_explanation_text(self,
                                   heatmap: np.ndarray,
                                   prediction: float,
                                   predicted_class: str) -> str:
        """
        íˆíŠ¸ë§µ ê¸°ë°˜ ì„¤ëª… í…ìŠ¤íŠ¸ ìƒì„±

        Args:
            heatmap: Grad-CAM íˆíŠ¸ë§µ
            prediction: ì˜ˆì¸¡ í™•ë¥ 
            predicted_class: ì˜ˆì¸¡ í´ë˜ìŠ¤

        Returns:
            ì„¤ëª… í…ìŠ¤íŠ¸
        """
        # íˆíŠ¸ë§µì—ì„œ ìµœëŒ€ í™œì„±í™” ì˜ì—­ ì°¾ê¸°
        max_activation = heatmap.max()
        threshold = 0.7 * max_activation  # ìƒìœ„ 30% í™œì„±í™” ì˜ì—­

        # í™œì„±í™” ì˜ì—­ì˜ ì¤‘ì‹¬ì  ê³„ì‚°
        high_activation_mask = (heatmap >= threshold).astype(np.uint8)
        y_coords, x_coords = np.where(high_activation_mask > 0)

        if len(y_coords) > 0:
            center_y = int(np.mean(y_coords))
            center_x = int(np.mean(x_coords))

            # ë‡Œ ì˜ì—­ ì¶”ì • (ê°„ë‹¨í•œ 4ë¶„ë©´ ë¶„í• )
            h, w = heatmap.shape
            region = self._localize_brain_region(center_x, center_y, w, h)
        else:
            region = "ì „ì²´ ì˜ì—­"

        # ì‹ ë¢°ë„
        confidence = prediction if prediction >= 0.5 else 1 - prediction

        # ì„¤ëª… í…ìŠ¤íŠ¸ êµ¬ì„±
        if predicted_class == "hemorrhage":
            explanation = f"""
**ì§„ë‹¨ ê²°ê³¼: ë‡Œì¶œí˜ˆ ì˜ì‹¬**

- **ì‹ ë¢°ë„**: {confidence*100:.1f}%
- **ì£¼ìš” ê´€ì‹¬ ì˜ì—­**: {region}
- **ë¶„ì„**: ë¹¨ê°„ìƒ‰ìœ¼ë¡œ í‘œì‹œëœ ë¶€ìœ„ì—ì„œ ê³ ë°€ë„ ì˜ì—­ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. \
ì´ëŠ” ë‡Œì¶œí˜ˆì˜ íŠ¹ì§•ì ì¸ íŒ¨í„´ê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤.

âš ï¸ **ì£¼ì˜**: ì´ ê²°ê³¼ëŠ” ë³´ì¡° ì§„ë‹¨ ë„êµ¬ë¡œë§Œ ì‚¬ìš©ë˜ì–´ì•¼ í•˜ë©°, \
ì „ë¬¸ì˜ì˜ ìµœì¢… íŒë‹¨ì„ ëŒ€ì²´í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
            """.strip()
        else:
            explanation = f"""
**ì§„ë‹¨ ê²°ê³¼: ì •ìƒ**

- **ì‹ ë¢°ë„**: {confidence*100:.1f}%
- **ë¶„ì„**: ë‡Œì¶œí˜ˆì„ ì‹œì‚¬í•˜ëŠ” íŠ¹ì´ ì†Œê²¬ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.

âœ… **ì°¸ê³ **: ì •ìƒ ì†Œê²¬ì´ì§€ë§Œ, ì„ìƒ ì¦ìƒì´ ìˆë‹¤ë©´ ì „ë¬¸ì˜ ìƒë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤.
            """.strip()

        return explanation

    def _localize_brain_region(self,
                               x: int, y: int,
                               width: int, height: int) -> str:
        """
        ë‡Œ ì˜ì—­ ì¶”ì • (ê°„ë‹¨í•œ 4ë¶„ë©´ + ì¤‘ì•™)

        Args:
            x, y: ì¤‘ì‹¬ ì¢Œí‘œ
            width, height: ì´ë¯¸ì§€ í¬ê¸°

        Returns:
            ì˜ì—­ ì„¤ëª…
        """
        # 9ë¶„ë©´ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
        w_third = width / 3
        h_third = height / 3

        # ì¢Œìš° êµ¬ë¶„
        if x < w_third:
            lr = "ì¢Œì¸¡"
        elif x > 2 * w_third:
            lr = "ìš°ì¸¡"
        else:
            lr = "ì¤‘ì•™"

        # ìƒí•˜ êµ¬ë¶„
        if y < h_third:
            tb = "ìƒë¶€"
        elif y > 2 * h_third:
            tb = "í•˜ë¶€"
        else:
            tb = "ì¤‘ê°„ë¶€"

        # ì˜ì—­ ë§¤í•‘ (ê°„ë‹¨í•œ ë²„ì „)
        region_map = {
            ("ì¢Œì¸¡", "ìƒë¶€"): "ì¢Œì¸¡ ì „ë‘ì—½",
            ("ì¤‘ì•™", "ìƒë¶€"): "ì „ë‘ì—½ ì¤‘ì•™",
            ("ìš°ì¸¡", "ìƒë¶€"): "ìš°ì¸¡ ì „ë‘ì—½",
            ("ì¢Œì¸¡", "ì¤‘ê°„ë¶€"): "ì¢Œì¸¡ ì¸¡ë‘ì—½/ë‘ì •ì—½",
            ("ì¤‘ì•™", "ì¤‘ê°„ë¶€"): "ê¸°ì €í•µ/ì‹œìƒ",
            ("ìš°ì¸¡", "ì¤‘ê°„ë¶€"): "ìš°ì¸¡ ì¸¡ë‘ì—½/ë‘ì •ì—½",
            ("ì¢Œì¸¡", "í•˜ë¶€"): "ì¢Œì¸¡ í›„ë‘ì—½/ì†Œë‡Œ",
            ("ì¤‘ì•™", "í•˜ë¶€"): "ë‡Œê°„/ì†Œë‡Œ",
            ("ìš°ì¸¡", "í•˜ë¶€"): "ìš°ì¸¡ í›„ë‘ì—½/ì†Œë‡Œ",
        }

        return region_map.get((lr, tb), f"{lr} {tb}")


def visualize_gradcam(result: dict, figsize: Tuple[int, int] = (15, 5)):
    """
    Grad-CAM ê²°ê³¼ ì‹œê°í™”

    Args:
        result: GradCAM.explain_prediction() ê²°ê³¼
        figsize: Figure í¬ê¸°
    """
    fig, axes = plt.subplots(1, 3, figsize=figsize)

    # ì›ë³¸ ì´ë¯¸ì§€
    axes[0].imshow(result['original'], cmap='gray' if len(result['original'].shape) == 2 else None)
    axes[0].set_title('Original Image')
    axes[0].axis('off')

    # íˆíŠ¸ë§µ
    axes[1].imshow(result['heatmap'], cmap='jet')
    axes[1].set_title('Grad-CAM Heatmap')
    axes[1].axis('off')

    # ì˜¤ë²„ë ˆì´
    axes[2].imshow(result['overlay'])
    axes[2].set_title(f"Prediction: {result['predicted_class']} ({result['confidence']*100:.1f}%)")
    axes[2].axis('off')

    plt.tight_layout()
    plt.show()

    # ì„¤ëª… ì¶œë ¥
    print("\n" + "="*60)
    print(result['explanation'])
    print("="*60)


# ============================================================
# ê°„í¸ ì‚¬ìš© í•¨ìˆ˜
# ============================================================

def explain_with_gradcam(model: keras.Model,
                        image_path: str,
                        preprocessor,
                        save_path: Optional[str] = None) -> dict:
    """
    Grad-CAMì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ ì„¤ëª… (ê°„í¸ ì¸í„°í˜ì´ìŠ¤)

    Args:
        model: í•™ìŠµëœ ëª¨ë¸
        image_path: ì´ë¯¸ì§€ ê²½ë¡œ
        preprocessor: CTImagePreprocessor ì¸ìŠ¤í„´ìŠ¤
        save_path: ê²°ê³¼ ì €ì¥ ê²½ë¡œ (Noneì´ë©´ ì €ì¥ ì•ˆí•¨)

    Returns:
        ì„¤ëª… ê²°ê³¼ dict
    """
    gradcam = GradCAM(model)
    result = gradcam.explain_prediction(image_path, preprocessor)

    # ì‹œê°í™”
    visualize_gradcam(result)

    # ì €ì¥
    if save_path:
        cv2.imwrite(save_path, cv2.cvtColor(result['overlay'], cv2.COLOR_RGB2BGR))
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {save_path}")

    return result


if __name__ == "__main__":
    print("Grad-CAM ëª¨ë“ˆ")
    print("ì‚¬ìš© ì˜ˆì‹œ:")
    print("  from gradcam_utils import GradCAM, explain_with_gradcam")
    print("  from preprocessing_utils import CTImagePreprocessor")
    print()
    print("  preprocessor = CTImagePreprocessor()")
    print("  result = explain_with_gradcam(model, 'image.jpg', preprocessor)")
